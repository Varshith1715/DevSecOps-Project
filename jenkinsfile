pipeline {
    agent any

    parameters {
        string(name: 'IMAGE_TAG', defaultValue: 'latest', description: 'Docker image tag')
        string(name: 'LOAD_BALANCER_IP', defaultValue: 'a3ab7de2f5bf24581a97de6ad05ad917-94003071.us-east-1.elb.amazonaws.com', description: 'Public IP or DNS of LoadBalancer service')
        string(name: 'RELEASE_NAME', defaultValue: 'taxi-booking', description: 'Helm release name')
    }

    environment {
        IMAGE_NAME               = "taxi-booking"
        DOCKERHUB_CREDENTIALS_ID = 'dockerhub'
        DOCKERHUB_USER           = 'varshith999'
        KUBE_NAMESPACE           = "default"
        CHART_PATH               = "${env.WORKSPACE}/terraform/web-app-chart"
        KUBE_CONFIG_PATH         = "/var/lib/jenkins/.kube/config"
        ZAP_TARGET               = "http://${params.LOAD_BALANCER_IP}:8080"
        ZAP_PATH                 = '/var/lib/jenkins/workspace/zap'  // Update to the actual path of ZAP installation
    }

    stages {
        stage('Checkout Code') {
            steps {
                checkout scm
            }
        }

        stage('Static Code Analysis - Semgrep') {
            steps {
                sh '''
                    echo "üîç Running Semgrep..."
                    docker run --rm -v $(pwd):/src returntocorp/semgrep semgrep scan --config=auto /src || echo "‚ö†Ô∏è Semgrep scan failed or had issues."
                '''
            }
        }

        stage('Build Docker Image from Existing WAR') {
            steps {
                script {
                    def imageExists = sh(
                        script: "docker images -q ${DOCKERHUB_USER}/${IMAGE_NAME}:${params.IMAGE_TAG}",
                        returnStdout: true
                    ).trim()

                    if (imageExists) {
                        echo "‚úÖ Docker image already exists locally. Skipping build."
                    } else {
                        sh """
                            echo "üì¶ Building Docker image from WAR..."
                            WAR_FILE_PATH="taxi-booking/target/taxi-booking-1.0.1.war"
                            if [ ! -f \$WAR_FILE_PATH ]; then
                                echo "‚ùå WAR file not found at \$WAR_FILE_PATH"
                                exit 1
                            fi
                            cp \$WAR_FILE_PATH ./app.war
                            docker build -t ${DOCKERHUB_USER}/${IMAGE_NAME}:${params.IMAGE_TAG} .
                        """
                    }
                }
            }
        }

        stage('Update Trivy DB') {
            steps {
                sh "docker run --rm aquasec/trivy image --download-db-only"
            }
        }

        stage('Scan Docker Image - Trivy') {
            steps {
                script {
                    def imageId = sh(script: "docker images -q ${DOCKERHUB_USER}/${IMAGE_NAME}:${params.IMAGE_TAG}", returnStdout: true).trim()
                    echo "üîç Scanning image ID: ${imageId}"
                    sh """
                        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
                            aquasec/trivy image --severity HIGH,CRITICAL --exit-code 1 ${imageId} || echo "‚ö†Ô∏è Trivy scan found issues or failed. Proceeding anyway."
                    """
                }
            }
        }

        stage('Push to DockerHub') {
            steps {
                withCredentials([usernamePassword(credentialsId: "${DOCKERHUB_CREDENTIALS_ID}", passwordVariable: 'DOCKER_PASSWORD', usernameVariable: 'DOCKER_USERNAME')]) {
                    sh """
                        echo "üîê Logging in to DockerHub..."
                        echo "\${DOCKER_PASSWORD}" | docker login -u "\${DOCKER_USERNAME}" --password-stdin
                        docker push \${DOCKER_USERNAME}/\${IMAGE_NAME}:${params.IMAGE_TAG}
                    """
                }
            }
        }

        stage('Helm Lint and Dry-Run') {
            steps {
                script {
                    if (!fileExists("${CHART_PATH}/Chart.yaml")) {
                        error "‚ùå Helm chart not found at ${CHART_PATH}"
                    }

                    sh """
                        echo "üß™ Linting and dry-running Helm chart..."
                        helm lint ${CHART_PATH} || echo "‚ö†Ô∏è Helm lint warnings"
                        helm upgrade --install ${params.RELEASE_NAME} ${CHART_PATH} \
                            --set image.repository=${DOCKERHUB_USER}/${IMAGE_NAME} \
                            --set image.tag=${params.IMAGE_TAG} \
                            --namespace ${KUBE_NAMESPACE} \
                            --kubeconfig ${KUBE_CONFIG_PATH} \
                            --dry-run || echo "‚ö†Ô∏è Helm dry-run failed, continuing..."
                    """
                }
            }
        }

        stage('Deploy to EKS using Helm') {
            steps {
                sh """
                    echo "üöÄ Deploying Helm chart to EKS..."
                    helm upgrade --install ${params.RELEASE_NAME} ${CHART_PATH} \
                        --set image.repository=${DOCKERHUB_USER}/${IMAGE_NAME} \
                        --set image.tag=${params.IMAGE_TAG} \
                        --namespace ${KUBE_NAMESPACE} \
                        --kubeconfig ${KUBE_CONFIG_PATH}
                """
            }
        }

        stage('DAST Scan with OWASP ZAP') {
            steps {
                echo "üîí Running OWASP ZAP scan on: ${env.ZAP_TARGET}"
                sh """
                    echo "üîç Starting ZAP in daemon mode..."
                    ${ZAP_PATH}/zap.sh -daemon -config api.disablekey=true
                    echo "üîç Running ZAP scan..."
                    ${ZAP_PATH}/zap-baseline.py -t ${ZAP_TARGET} -g /tmp/gen.conf \
                        -r /tmp/zap-report.html -x /tmp/zap-report.xml \
                        --auto -l FAIL -I
                    echo "üìÑ Reports generated at: /tmp/zap-report.html"
                    mv /tmp/zap-report.* ${WORKSPACE}/
                """
            }
            post {
                always {
                    archiveArtifacts artifacts: 'zap-report.*', allowEmptyArchive: true
                }
            }
        }

        stage('Install OPA Gatekeeper') {
            steps {
                sh """
                    echo "üîê Installing OPA Gatekeeper if not already installed..."
                    if ! kubectl get pods -n gatekeeper-system --kubeconfig ${KUBE_CONFIG_PATH} &>/dev/null; then
                        kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/release-3.14/deploy/gatekeeper.yaml --kubeconfig ${KUBE_CONFIG_PATH}
                        kubectl rollout status deployment/gatekeeper-controller-manager -n gatekeeper-system --kubeconfig ${KUBE_CONFIG_PATH}
                    else
                        echo "‚úÖ OPA Gatekeeper already installed."
                    fi

                    ATTEMPTS=0
                    until kubectl get crd constrainttemplates.templates.gatekeeper.sh --kubeconfig ${KUBE_CONFIG_PATH} &>/dev/null || [ \$ATTEMPTS -eq 10 ]; do
                        echo "‚è≥ Waiting for ConstraintTemplate CRD..."
                        ATTEMPTS=\$((ATTEMPTS+1))
                        sleep 10
                    done

                    if ! kubectl get crd constrainttemplates.templates.gatekeeper.sh --kubeconfig ${KUBE_CONFIG_PATH} &>/dev/null; then
                        echo "‚ùå ConstraintTemplate CRD not available after waiting. Skipping OPA checks."
                    else
                        echo "‚úÖ ConstraintTemplate CRD is ready."
                    fi
                """
            }
        }

        stage('Apply OPA Constraints & Templates') {
            steps {
                sh """
                    echo "üìú Applying OPA constraint templates and constraints..."
                    kubectl apply -f opa/policies/privileged-template.yaml --kubeconfig ${KUBE_CONFIG_PATH} || true
                    kubectl apply -f opa/policies/privileged-constraint.yaml --kubeconfig ${KUBE_CONFIG_PATH} || true
                    kubectl apply -f opa/policies/trusted-registry-template.yaml --kubeconfig ${KUBE_CONFIG_PATH} || true
                    kubectl apply -f opa/policies/trusted-registry-constraint.yaml --kubeconfig ${KUBE_CONFIG_PATH} || true
                """
            }
        }

        stage('OPA Gatekeeper Policy Check') {
            steps {
                sh """
                    echo "üîç Checking for OPA policy violations..."
                    VIOLATIONS=\$(kubectl get constraints -A --kubeconfig ${KUBE_CONFIG_PATH} -o json | jq '.items[] | .status.totalViolations' | grep -v null | awk '\$1 > 0')
                    if [ -n "\$VIOLATIONS" ]; then
                        echo "‚ö†Ô∏è Policy violations found, skipping failure..."
                    else
                        echo "‚úÖ No policy violations found."
                    fi
                """
            }
        }
    }

    post {
        success {
            echo "‚úÖ Pipeline completed successfully!"
            slackSend (
                channel: 'ci-cd-pipeline',
                color: 'good',
                message: "‚úÖ *Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'* succeeded on `${env.NODE_NAME}`.\n<${env.BUILD_URL}|Click here> for details."
            )
        }
        failure {
            echo "‚ùå Pipeline failed. Check the logs for errors."
            slackSend (
                channel: 'ci-cd-pipeline',
                color: 'danger',
                message: "‚ùå *Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'* failed on `${env.NODE_NAME}`.\n<${env.BUILD_URL}|Click here> to see the failure logs."
            )
        }
    }
}
